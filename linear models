title: "Generalized linear Models (GAMs)"
author: "Ali Mirzaei"
date: "11/4/2022"
# Data set
MF_read_CsV<-function(path,use_UTF8=TRUE,choose_file=FALSE,set_max_overlaps=TRUE){
  if(set_max_overlaps){
    options(ggrepel.max.overlaps = Inf)
  }
  if(choose_file){
    path=file.choose()
  }
  if(use_UTF8){
    data<- read.csv(path,encoding="UTF-8")
  }else{
    data<- read.csv(path)
  }
  
  return(data)
}

df<- MF_read_CsV(path="C:/Users/Traffic/Desktop/SOHBATZADEH/esfahan-data-98-final.csv")
View(df)

#Plot Accidents time series
plot(df$acc_total, main = "Time series",type = "l")
#pairs plot 
```{r pairs plot}
corrplot(
  cor(df %>% select(-JDATE,-JYEAR, -TAG,
                    -JMONTH, -JDAY, -JDATE,
                    -IS_HOLIDAY, -DESCRIPTION,
                   )),
  method = 'square',
  type = 'upper',
  tl.col = 'black',
  tl.cex = 0.75, tl.srt = 90,
  col = colorRampPalette(c('purple', 'dark green'))(200)
)
```
#model0
mode10 <- lm(acc_total ~ 
              TOTAL_VEHICLES, data=df) 
# 
summary(mode10 )
#
#model plot
```{r model plot}
par(mfrow=c(2,2)) # split the graphics device into 4 panels
plot(modl0) # (uses plot.lm as modl0 is class ‘lm’)
# diagnostic plots one by one.
-1. Residuals vs Fitted
This plot shows if residuals have non-linear patterns.
2. Normal Q-Q
This plot shows if residuals are normally distributed. 
3. Scale-Location
It’s also called Spread-Location plot. This is how you can check the assumption of equal variance (homoscedasticity).
4. Residuals vs Leverage
This plot helps us to find influential cases (i.e., subjects) if any.
```
#AIC 
```{R AIC }
AIC(modl0) # Selecting models in order to minimize Akaike’s Information Criterion (AIC) is one way of trying to do this.
```
#model selection 
##lm modl1
```{r lm1}
modl1 <- lm(acc_total ~ 
              SPEED_VIOLATIONS, data=df)
summary(modl1 )
##AIC FOR TWO MODEL
```{r model selection}
AIC(modl1,modl0)
```
# Specifying an 80-20 train-test split
```{r test data}
train_idx = createDataPartition(df$SPEED_VIOLATIONS, p = .8, list = F)
train = df[train_idx, ]
test = df[-train_idx, ]
print(test)
```
# Declaring the trainControl function
```{r trainControl function}
train_ctrl = trainControl(
  method  = "cv", #Specifying Cross validation
  number  = 2, # Specifying 5-fold
  verboseIter = TRUE, # So that each iteration you get an update of the progress
  classProbs = TRUE # So that you can obtain the probabilities for each example
)
rf_model = train(
  acc_total ~SPEED_VIOLATIONS, # Specifying the response variable and the feature variables
  method = "rf", # Specifying the model to use
  data = train, 
  trControl = train_ctrl
)
```
#prediction 
```{r pred}
predictions = predict(rf_model, newdata = test)
print(predictions)
```





## factor variables
Notice how R reports an intercept parameter and parameters for the two treatment
levels, but, in order to obtain an identifiable model, it has not included a parameter
for the control level of the group factor.
TAG is a factor variable in my data.
df$TAG <- as.factor(df$TAG)
fit <- lm(accident ~ TAG , data=df)
summary(fit)
par(mfrow=c(3,3))
plot(fit) # Then R will show you four diagnostic plots one by one:1. Residuals vs Fitted,2. Normal Q-Q,3. Scale-Location,4. Residuals vs Leverage
#https://data.library.virginia.edu/diagnostic-plots/
## Measures of Influence
olsrr offers the following tools to detect influential observations:
-Cook’s D Bar Plot
-Cook’s D Chart
-DFBETAs Panel
-DFFITs Plot
-Studentized Residual Plot
-Standardized Residual Chart
-Studentized Residuals vs Leverage Plot
-Deleted Studentized Residual vs Fitted Values Plot
-Hadi Plot
-Potential Residual Plot

ols_plot_cooksd_bar(mod_lm)  # A data point having a large cook’s d indicates that the data point strongly influences the fitted values.
ols_plot_dfbetas(mod_lm)
ols_plot_resid_stud(mod_lm)
ols_plot_resid_lev(mod_lm)
ols_plot_resid_stud_fit(mod_lm)
ols_plot_resid_pot(mod_lm)
## How to calculate the 95% confidence interval for the slope
confint(mod_lm, 'SPEED_VIOLATIONS', level=0.95)
