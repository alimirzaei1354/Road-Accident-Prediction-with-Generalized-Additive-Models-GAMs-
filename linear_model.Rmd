---
title: "lm_accident_prediction"
author: "Ali_Mirzaei"
date: "2022-11-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r library}
library('caret')
```
#data explantory
```{r data}
glimpse(df)
```


#plot Accidents for 365 dayes
```{r plot accidents}
plot(df$acc_total, main = "Time series",type = "l")
```
#lm model0 
```{r lm}
modl0 <- lm(acc_total ~ 
              TOTAL_VEHICLES, data=df)
summary(modl0 )
```
#residuals
```{r residuals}
plot(fitted(modl0),residuals(modl0), xlab="fitted values",ylab="residuals")
```
#confidence interval for coefficients
```{r confidence interval}
confint(modl0, 'TOTAL_VEHICLES', level=0.95)
```
#pairs plot 
```{r pairs plot}
corrplot(
  cor(df %>% select(-JDATE,-JYEAR, -TAG,
                    -JMONTH, -JDAY, -JDATE,
                    -IS_HOLIDAY, -DESCRIPTION,
                   )),
  method = 'square',
  type = 'upper',
  tl.col = 'black',
  tl.cex = 0.75, tl.srt = 90,
  col = colorRampPalette(c('purple', 'dark green'))(200)
)
```
#model matrix
```{r model matrix}
model.matrix(modl0)
```
#model plot
```{r model plot}
par(mfrow=c(2,2)) # split the graphics device into 4 panels
plot(modl0) # (uses plot.lm as modl0 is class ‘lm’)
```
#AIC 
```{R AIC }
AIC(modl0)
```
#model selection 
##lm modl1
```{r lm1}
modl1 <- lm(acc_total ~ 
              SPEED_VIOLATIONS, data=df)
summary(modl1 )
```
##AIC FOR TWO MODEL
```{r model selection}
AIC(modl1,modl0)
```
# Specifying an 80-20 train-test split
```{r test data}
train_idx = createDataPartition(df$SPEED_VIOLATIONS, p = .8, list = F)
train = df[train_idx, ]
test = df[-train_idx, ]
print(test)
```
# Declaring the trainControl function
```{r trainControl function}
train_ctrl = trainControl(
  method  = "cv", #Specifying Cross validation
  number  = 2, # Specifying 5-fold
  verboseIter = TRUE, # So that each iteration you get an update of the progress
  classProbs = TRUE # So that you can obtain the probabilities for each example
)
rf_model = train(
  acc_total ~SPEED_VIOLATIONS, # Specifying the response variable and the feature variables
  method = "rf", # Specifying the model to use
  data = train, 
  trControl = train_ctrl
)
```

## Get the predictions of your model in the test set 
```{r pred}
predictions = predict(rf_model, newdata = test)
print(predictions)
```
## factor variables
Notice how R reports an intercept parameter and parameters for the two treatment
levels, but, in order to obtain an identifiable model, it has not included a parameter
for the control level of the group factor.
TAG is a factor variable in my data.
```{r factor}
df$TAG <- as.factor(df$TAG)
fit <- lm(acc_total ~ TAG , data=df)
summary(fit)
par(mfrow=c(3,3))
plot(fit) # Then R will show you four diagnostic plots one by one:1. Residuals vs Fitted,2. Normal Q-Q,3. Scale-Location,4. Residuals vs Leverage
```
## Measures of Influence
```{r Influence}
library(olsrr)
par(mfrow=c(1,6))
ols_plot_cooksd_bar(modl1)
ols_plot_dfbetas(modl1)
ols_plot_resid_stud(modl1)
ols_plot_resid_lev(modl1)
ols_plot_resid_stud_fit(modl1)
ols_plot_resid_pot(modl1)
```
#confint
```{r confidence interval}
confint(modl1, 'SPEED_VIOLATIONS', level=0.95)
```
# LINEAR MIX MODEL (random effect)
A fundamental question is, what effect does vacation have on accidents? Does it have a fixed effector random ?
```{r random effect}
m0 <- lm(acc_total ~ IS_HOLIDAY , df)
m1 <- lm(acc_total ~ IS_HOLIDAY + TAG, df)
m2 <- lm(acc_total ~  TAG, df)
anova(m0,m1,m2)
## there is strong evidence for TAG to TAG differences, which means that with
this model we can not tell whether IS_HOLIDAY had an effect or not.
## The IS_HOLIDAY effects are fixed characteristics of the
whole population of TAG that we are trying to learn about. In contrast, the TAG effect
will vary randomly from TAG to TAG in the population.
```
# test effect
```{r test effect}
df1 <- df %>% select(TAG, acc_total, IS_HOLIDAY)
st <- aggregate(data.matrix(df1),
                by=list(TAG=df1$TAG),mean)
m3 <- lm(acc_total ~ IS_HOLIDAY, st)
anova(m3) # There is strong evidence for a IS_HOLIDAY effect here,
summary(m3)$sigma^2 - summary(m1)$sigma^2/4
```
#intraction plot 
```{r }
df1 <- df %>% select(TAG,avg_class4_speed, acc_total)
attach(df1)
interaction.plot(avg_class4_speed,TAG, acc_total)
## JWEEKDAYNAME intraction 
df1 <- df %>% select(JWEEKDAYNAME,
                     class5, acc_total)
attach(df1)
interaction.plot(x.factor =df1$class5, #x-axis variable
                 trace.factor = df1$JWEEKDAYNAME, #variable for lines
                 response = df1$acc_total, #y-axis variable
                 fun = median, #metric to plot
                 ylab = "acc",
                 xlab = "class5",
                 col = c("yellow", "blue","red","green","Purple","black"),
                 lty = 1, #line type
                 lwd = 2, #line width
                 trace.label = "Gender")
                
### anaysis of all factors for best selection
m0 <- lm(acc_total ~  TAG,df1)
m1 <- lm(acc_total ~ IS_HOLIDAY,df1)
m2 <- lm(acc_total ~  JWEEKDAYNAME,df1)
m3 <- lm(acc_total ~ IS_HOLIDAY+TAG,df1)
m4 <- lm(acc_total ~  IS_HOLIDAY+JWEEKDAYNAME,df1)
m5 <- lm(acc_total ~  TAG+JWEEKDAYNAME,df1)
anova(m0,m1,m2,m3,m4,m5)
### sig analysis 
m6 <- lm(acc_total ~ 1,st1)
sig <- summary(m0)$sigma
sigb <- (summary(m6)$sigma^2 - sig^2/3)^0.5
sig
sigb
# So, there is a fairly large amount of rail to rail variability, whereas the measurement
# error is relatively small.
```
#Visually assessing model assumptions
```{r Visually assessing model assumptions}
tdat <- data.frame(predicted=predict(mod), residual = residuals(mod), referrer=df$IS_HOLIDAY)
ggplot(tdat1,aes(x=predicted,y=residual, colour=referrer)) + geom_point() + geom_hline(yintercept=0, lty=3)
#qqplot
ggplot(tdat,aes(x=residual)) + geom_histogram(bins=20, color="black")
ggplot(tdat1,aes(sample=residual)) + stat_qq() + stat_qq_line()

```
# Random intercepts and slopes for random effect 
```{r  Random intercepts and slopes}
modg <- lme4::lmer(acc_total ~ SPEED_VIOLATIONS + (1 +SPEED_VIOLATIONS|IS_HOLIDAY), data=df)
df$acc_total2 <- predict(modg)
ggplot(df,aes(x=SPEED_VIOLATIONS,y=acc_total2,colour=IS_HOLIDAY, group=IS_HOLIDAY)) + geom_point() + geom_line() + theme(legend.position="bottom", legend.direction = "horizontal") 
```
#Using ‘buildmer’ to automatically find & compare maximal (mixed) models
```{r buildmer}
m0 <- buildmer(acc_scal~SPEED_scal*dist_scal*HEAVY_scal+(SPEED_scal|IS_HOLIDAY)+(polic_scal|IS_HOLIDAY),data = df,buildmerControl=buildmerControl(direction='order',
                                                                                                                                                 args=list(control=lmerControl(optimizer='bobyqa'))))
(f <- formula(m0@model))
summary(m)
```
